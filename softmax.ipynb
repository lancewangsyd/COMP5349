{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "softmax.ipynb",
      "version": "0.3.2",
      "views": {},
      "default_view": {},
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "MotBNCuImBVi",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def relu(Z):\n",
        "  \n",
        "  \"\"\"\n",
        "  Arguments:\n",
        "  Z -- output of linear layer, with shape(n,m), n is number of units\n",
        "  \n",
        "  Returns:\n",
        "  A -- relu result of Z\n",
        "  cache -- \n",
        "  \"\"\"\n",
        "  \n",
        "  A=np.maximum(0,Z)\n",
        "  \n",
        "  assert(A.shape == Z.shape)\n",
        "  \n",
        "  cache = Z\n",
        "  return A, cache"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qvg5eSLDsmah",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "90ef9515-8561-465a-ff4c-fb5829f4eb5e",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1524457771774,
          "user_tz": -600,
          "elapsed": 743,
          "user": {
            "displayName": "Lan",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "106352409797232494979"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "def relu_backward(dA, cache):\n",
        "    \"\"\"\n",
        "    Implement the backward propagation for a single RELU unit.\n",
        " \n",
        "    Arguments:\n",
        "    dA -- post-activation gradient, of any shape\n",
        "    cache -- 'Z' where we store for computing backward propagation efficiently\n",
        "\n",
        "    Returns:\n",
        "    dZ -- Gradient of the cost with respect to Z\n",
        "    \"\"\"\n",
        "    \n",
        "    Z = cache\n",
        "    dZ = np.array(dA, copy=True) # just converting dz to a correct object.\n",
        "    \n",
        "    # When z <= 0, you should set dz to 0 as well. \n",
        "    dZ[Z <= 0] = 0\n",
        "    \n",
        "    assert (dZ.shape == Z.shape)\n",
        "    \n",
        "    return dZ\n",
        "  \n",
        " "
      ],
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 1, 3],\n",
              "       [2, 2, 3],\n",
              "       [2, 1, 3],\n",
              "       [5, 1, 3]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 120
        }
      ]
    },
    {
      "metadata": {
        "id": "W5F3EU_0LDr3",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def softmax(Z):\n",
        "  '''\n",
        "  implements softmax funciton\n",
        "  \n",
        "  Arguments:\n",
        "  Z -- input as an array of shape(n,1)\n",
        "  \n",
        "  Returns:\n",
        "  A -- softmax result of array z, same shape as z\n",
        "  cache -- A. \n",
        "  '''\n",
        "  A=np.exp(Z)/np.sum(np.exp(Z),axis=0)\n",
        "  cache=Z\n",
        "  assert(A.shape == Z.shape)\n",
        "  return A, cache"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "buCOMoM0Tbfc",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "04ab46e8-a22e-4a95-c2f8-5e20386c9e36",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1524399996718,
          "user_tz": -600,
          "elapsed": 675,
          "user": {
            "displayName": "Lan",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "106352409797232494979"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def softmax_to_label(A):\n",
        "  p=A.argmax(axis=0)\n",
        "  return p\n",
        "print(softmax_to_label(q))"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[3 1 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "XFVjXGq-P_28",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def softmax_backward(Y, cache):\n",
        "  \"\"\"\n",
        "  softmax backward for \n",
        "  \n",
        "  \"\"\"\n",
        "  \n",
        "  Z = cache\n",
        "  \n",
        "  dZ = softmax(Z)-Y "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mZ8AT4z9DeSX",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def cross_entropy(AL, Y):\n",
        "  \"\"\"\n",
        "  Calculate cross entropy\n",
        "  \n",
        "  Arguments:\n",
        "  AL -- output of model:probability vector, shape (10, m)\n",
        "  Y -- true label vector, shape of (10,m)\n",
        "  \n",
        "  Returns:\n",
        "  cost -- cross entropy cost\n",
        "  \n",
        "  \"\"\"\n",
        "  \n",
        "  m=Y.shape[1]\n",
        "  assert (AL.shape == Y.shape)\n",
        "  cost = -np.sum(np.log(AL)*Y)/m\n",
        "  \n",
        "  #cost =np.squeeze(cost)\n",
        "  #assert (cost.shape == ())\n",
        "  return cost"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qHpZkr22FkFK",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "AL=np.random.rand(10,2)\n",
        "AL\n",
        "\n",
        "Y=np.random.rand(10,2)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qCwCquOfK_pn",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "e74d23fb-34c9-4f6a-c98b-890e564ec81f",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1524448182691,
          "user_tz": -600,
          "elapsed": 709,
          "user": {
            "displayName": "Lan",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "106352409797232494979"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "sum=0\n",
        "for i,j in zip(AL[:,0],Y[:,0]):\n",
        "  print(np.log(i)*j)\n",
        "  sum+=np.log(i)*j\n",
        "for i,j in zip(AL[:,1],Y[:,1]):\n",
        "  print(np.log(i)*j)\n",
        "  sum+=np.log(i)*j\n",
        "-sum/2"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-2.070676304725382\n",
            "-0.12242334322964535\n",
            "-0.5337503172670137\n",
            "-0.4954385158793055\n",
            "-0.39008039781808346\n",
            "-0.14470585316615525\n",
            "-0.10771245757524081\n",
            "-0.5192014409628475\n",
            "-0.024243082213134842\n",
            "-0.8705443534852548\n",
            "-0.20301065396042672\n",
            "-0.10858596937551737\n",
            "-0.07412327842500935\n",
            "-1.1473955390071593\n",
            "-0.10819410093309748\n",
            "-0.047213625645892564\n",
            "-0.6378015938057204\n",
            "-0.10422165444358063\n",
            "-0.0004193959895334778\n",
            "-0.3486660445891896\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4.029203961248596"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 83
        }
      ]
    },
    {
      "metadata": {
        "id": "JIk82nbhF-P0",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "cef2c549-9e16-4670-ca5e-fd314aeb8589",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1524447995229,
          "user_tz": -600,
          "elapsed": 757,
          "user": {
            "displayName": "Lan",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "106352409797232494979"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "(-np.dot(Y[:,0],np.log(AL[:,0]).T)-np.dot(Y[:,1],np.log(AL[:,1]).T))/2"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4.029203961248594"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        }
      ]
    },
    {
      "metadata": {
        "id": "cweiVbqFKGfZ",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "90566db9-06e8-4758-fd67-c42fbe175819",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1524448092350,
          "user_tz": -600,
          "elapsed": 693,
          "user": {
            "displayName": "Lan",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "106352409797232494979"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "np.dot(np.log(AL).T,Y)"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-5.27877607, -3.02392247],\n",
              "       [-4.3085474 , -2.77963186]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 81
        }
      ]
    },
    {
      "metadata": {
        "id": "hclooT8EMDjo",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "11c76859-707e-4a56-ed7e-dee36910a1b6",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1524448747948,
          "user_tz": -600,
          "elapsed": 659,
          "user": {
            "displayName": "Lan",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "106352409797232494979"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "cross_entropy(AL,Y)"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4.029203961248595"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 88
        }
      ]
    },
    {
      "metadata": {
        "id": "4_M13nEJSMZt",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def L_model_backward(AL, Y, caches):\n",
        "  \"\"\"\n",
        "  Arguments:\n",
        "  AL --probability vector, output of forward prop, shape of (10,m)\n",
        "  Y -- true label vector, same shape as AL\n",
        "  caches -- \n",
        "  \"\"\"\n",
        "  grads={}\n",
        "  L=len(caches)\n",
        "  m=AL.shape[1]\n",
        "  \n",
        "  dAL = -np.divide(Y,AL)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tvN1786Nl5i6",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4Mvp9qUNl5UC",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def initialize_parameters_deep(layer_dims):\n",
        "  \"\"\"\n",
        "  Arguments:\n",
        "  layer_dims -- python array containing dimensions of each layer\n",
        "  \n",
        "  Returns:\n",
        "  parameters -- dictionary\n",
        "                Wl -- weight shape of (layer_dims[l], layer_dims[l-1])\n",
        "                bl -- bias shape of (layer_dims[l],1)\n",
        "                \n",
        "  \"\"\"\n",
        "  np.random.seed(1)\n",
        "  parameters = {}\n",
        "  \n",
        "  L=len(layer_dims)\n",
        "  \n",
        "  for l in np.arange(1,L,1):\n",
        "    parameters['W'+str(l)] = np.random.rand(layer_dims[l], layer_dims[l-1]) / np.sqrt(layer_dims[l-1])\n",
        "    parameters['b'+str(l)] = np.zeros((layer_dims[l],1))\n",
        "  \n",
        "    assert(parameters['W'+str(l)].shape == (layer_dims[l], layer_dims[l-1]))\n",
        "    assert(parameters['b'+str(l)].shape == (layer_dims[l], 1))\n",
        "  \n",
        "  return parameters"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "T8gpWakb7QBF",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def linear_forward(A, W, b):\n",
        "  \"\"\"\n",
        "  Arguments:\n",
        "  A -- activation result from layer l-1, shape of (layer_dims[l-1], m)\n",
        "  W -- weight for layer l shape of (layer_dims[l], layer_dims[l-1])\n",
        "  b -- bias for layer l shape of (layer_dims[l], 1)\n",
        "  \n",
        "  Returns:\n",
        "  Z -- linear result shape of (layer_dims[l], m)\n",
        "  cache -- A,W,b \n",
        "  \"\"\"\n",
        "  \n",
        "  \n",
        "  #Z=np.dot(W,A) + b\n",
        "  \n",
        "  Z = W.dot(A) +b\n",
        "  \n",
        "  assert(Z.shape == (W.shape[0], A.shape[1]) )\n",
        "  cache = (A, W, b)\n",
        "  \n",
        "  return Z, cache\n",
        "  \n",
        "  \n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DgVxtPH--v6h",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "6ce82242-7ea8-45cf-89bc-8cee684dab07",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1524464211756,
          "user_tz": -600,
          "elapsed": 981,
          "user": {
            "displayName": "Lan",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "106352409797232494979"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "np.random.seed(0)\n",
        "A1=np.random.randint(5,size =(4,2))\n",
        "W=np.random.rand(3,4)\n",
        "b=np.random.rand(3,1)\n",
        "\n",
        "linear_forward(A1,W,b)"
      ],
      "execution_count": 204,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[ 9.24513744,  5.18402155],\n",
              "        [10.10452066,  4.87593475],\n",
              "        [ 4.0826652 ,  2.92546433]]), (array([[4, 0],\n",
              "         [3, 3],\n",
              "         [3, 1],\n",
              "         [3, 2]]), array([[0.43758721, 0.891773  , 0.96366276, 0.38344152],\n",
              "         [0.79172504, 0.52889492, 0.56804456, 0.92559664],\n",
              "         [0.07103606, 0.0871293 , 0.0202184 , 0.83261985]]), array([[0.77815675],\n",
              "         [0.87001215],\n",
              "         [0.97861834]])))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 204
        }
      ]
    },
    {
      "metadata": {
        "id": "d4raBHxuAWG8",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def relu(Z):\n",
        "  \n",
        "  \"\"\"\n",
        "  Arguments:\n",
        "  Z -- output of linear layer, with shape(n,m), n is number of units\n",
        "  \n",
        "  Returns:\n",
        "  A -- relu result of Z\n",
        "  cache -- \n",
        "  \"\"\"\n",
        "  \n",
        "  A=np.maximum(0,Z)\n",
        "  \n",
        "  assert(A.shape == Z.shape)\n",
        "  \n",
        "  cache = Z\n",
        "  return A, cache\n",
        "\n",
        "def linear_activation_forward(A_prev, W, b, activation):\n",
        "  \"\"\"\n",
        "  \n",
        "  Arguments:\n",
        "  A_prev -- previous A result from layer l-1, shape of (layer_dims[l-1], m)\n",
        "  W -- weight for layer l shape of (layer_dims[l], layer_dims[l-1])\n",
        "  b -- bias for layer l shape of (layer_dims[l], 1)\n",
        "  activation -- relu/softmax\n",
        "  \n",
        "  Returns:\n",
        "  A -- \n",
        "  cache -- \n",
        "  \"\"\"\n",
        "  \n",
        "  Z, linear_cache = linear_forward(A_prev, W, b)\n",
        "  \n",
        "  if activation == \"relu\":\n",
        "    A, activation_cache = relu(Z)\n",
        "  if activation == \"softmax\":\n",
        "    A, activation_cache = softmax(Z)\n",
        "  \n",
        "  cache = (linear_cache, activation_cache)\n",
        "  return A, cache"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "u1IcC8sVLlqa",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "b99a5890-120a-45f0-e773-3e0013bdfb4a",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1524464774247,
          "user_tz": -600,
          "elapsed": 812,
          "user": {
            "displayName": "Lan",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "106352409797232494979"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "A1"
      ],
      "execution_count": 219,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[4, 0],\n",
              "       [3, 3],\n",
              "       [3, 1],\n",
              "       [3, 2]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 219
        }
      ]
    },
    {
      "metadata": {
        "id": "BwDLW0WJLnIv",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "11e700e5-efe5-4bf9-9bd6-b9c9d4e3d6c9",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1524464837723,
          "user_tz": -600,
          "elapsed": 702,
          "user": {
            "displayName": "Lan",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "106352409797232494979"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "W.dot(A1)+b"
      ],
      "execution_count": 223,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 9.24513744,  5.18402155],\n",
              "       [10.10452066,  4.87593475],\n",
              "       [ 4.0826652 ,  2.92546433]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 223
        }
      ]
    },
    {
      "metadata": {
        "id": "38Ec1LjVLov6",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "ce248d5d-b84a-400c-aa46-9a8d27c46b74",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1524464788178,
          "user_tz": -600,
          "elapsed": 749,
          "user": {
            "displayName": "Lan",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "106352409797232494979"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "b"
      ],
      "execution_count": 221,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.77815675],\n",
              "       [0.87001215],\n",
              "       [0.97861834]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 221
        }
      ]
    },
    {
      "metadata": {
        "id": "tl12_bl-A6VU",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "03d8e2b6-879e-49fe-e104-80c1b2c81377",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1524484897923,
          "user_tz": -600,
          "elapsed": 725,
          "user": {
            "displayName": "Lan",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "106352409797232494979"
          }
        }
      },
      "cell_type": "code",
      "source": [
        " linear_activation_forward(A1, W, b, \"relu\")\n"
      ],
      "execution_count": 246,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[ 9.24513744,  5.18402155],\n",
              "        [10.10452066,  4.87593475],\n",
              "        [ 4.0826652 ,  2.92546433]]), ((array([[4, 0],\n",
              "          [3, 3],\n",
              "          [3, 1],\n",
              "          [3, 2]]), array([[0.43758721, 0.891773  , 0.96366276, 0.38344152],\n",
              "          [0.79172504, 0.52889492, 0.56804456, 0.92559664],\n",
              "          [0.07103606, 0.0871293 , 0.0202184 , 0.83261985]]), array([[0.77815675],\n",
              "          [0.87001215],\n",
              "          [0.97861834]])),\n",
              "  array([[ 9.24513744,  5.18402155],\n",
              "         [10.10452066,  4.87593475],\n",
              "         [ 4.0826652 ,  2.92546433]])))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 246
        }
      ]
    },
    {
      "metadata": {
        "id": "DafLLO79OnkB",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def L_model_forward(X, parameters):\n",
        "  \"\"\"\n",
        "  Arguments:\n",
        "  X -- input data. shape of \n",
        "  parameters -- output from initialize_parameters_deep. dictionary contains:\n",
        "                Wl -- weight shape of (layer_dims[l], layer_dims[l-1])\n",
        "                bl -- bias shape of (layer_dims[l],1)\n",
        "  \n",
        "  Returns:\n",
        "  AL -- final output of shape (layer_dims[l], m)\n",
        "  \"\"\"\n",
        "  L = len(parameters)//2\n",
        "  \n",
        "  assert(X.shape[0] == parameters['W1'].shape[1])\n",
        "  \n",
        "  caches=[]\n",
        "  \n",
        "  A_prev = X\n",
        "  \n",
        "  for l in np.arange(1,L):\n",
        "  \n",
        "    A, linear_activation_cache = linear_activation_forward(A_prev, parameters['W'+str(l)], parameters['b'+str(l)], \"relu\")\n",
        "    A_prev = A\n",
        "    caches.append(linear_activation_cache)\n",
        "    #print(A_prev)\n",
        "  AL, linear_activation_cache =  linear_activation_forward(A_prev, parameters['W'+str(L)], parameters['b'+str(L)], \"softmax\")\n",
        "  caches.append(linear_activation_cache)\n",
        "  \n",
        "  #assert(AL.shape == (,))\n",
        "  return AL, caches"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NJEsoChJVL6_",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "layer_dims = np.array([3,3,5,10])\n",
        "parameters = initialize_parameters_deep(layer_dims)\n",
        "X=np.array([[1,2,3],[3,3,3]]).T\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bu7KgSrzWDqE",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "a15033da-584a-42e5-b275-19dc31ccafeb",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1524486460741,
          "user_tz": -600,
          "elapsed": 653,
          "user": {
            "displayName": "Lan",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "106352409797232494979"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "AL,c = L_model_forward(X, parameters)\n",
        "AL"
      ],
      "execution_count": 296,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.07723564, 0.06601342],\n",
              "       [0.12387982, 0.13197515],\n",
              "       [0.09780823, 0.09122959],\n",
              "       [0.14598184, 0.18562891],\n",
              "       [0.083619  , 0.07400222],\n",
              "       [0.0686272 , 0.05299894],\n",
              "       [0.08917162, 0.08123063],\n",
              "       [0.09937175, 0.09373668],\n",
              "       [0.11341527, 0.12089989],\n",
              "       [0.10088965, 0.10228456]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 296
        }
      ]
    },
    {
      "metadata": {
        "id": "V3kFXo29ew80",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def linear_backward(dZ, cache):\n",
        "  \"\"\"\n",
        "  Arguments:\n",
        "  dZ -- cost gradient with respect to linear output z (layer l)\n",
        "  cache  -- \n",
        "  \n",
        "  Returns -- \n",
        "  \n",
        "  \n",
        "  \"\"\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "c0vCi1T0fywZ",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "  \n",
        "\n",
        "class Network(object):\n",
        "  \n",
        "  def __init__(self, layer_dims, X, labels):\n",
        "    \"\"\"\n",
        "    Arguments: layer_dims -- python array containing dimensions of each layer. e.g. np.array[2,5,10]\n",
        "                          -- input layer = no. of attributes; hidden layer; output layer = no. of classes\n",
        "               Y -- true vectorized labels, shape (10,m)\n",
        "               \n",
        "               caches -- dictionary containing Z for l in (1,L+1),A for l in (0,L+1), Al - activation result for layer l, Zl - linear result for layer l\n",
        "                      -- with A for layer L being AL, A0=X\n",
        "    \"\"\"\n",
        "    self.X = X\n",
        "    \n",
        "    self.labels = labels\n",
        "    \n",
        "    self.layer_dims = layer_dims\n",
        "    \n",
        "    self.L = len(layer_dims)\n",
        "    \n",
        "    self.parameters = {}\n",
        "    \n",
        "    self.AL = 0\n",
        "    \n",
        "    self.Y = []\n",
        "    \n",
        "    self.m = 0\n",
        "    \n",
        "    self.grads = {}\n",
        "    \n",
        "    self.caches = {}\n",
        "    \n",
        "    self.cost=0\n",
        "    \n",
        "    self.p = []\n",
        "    \n",
        "  def vectorize_label(self):\n",
        "      #Y=np.zeros((10,1))\n",
        "      #Y[labels] =1.0\n",
        "      #return Y\n",
        "      \"\"\"\n",
        "      labels -- tru labels, array, e.g. [1,3,4]\n",
        "\n",
        "      \"\"\"\n",
        "      y_enc = (np.arange(np.max(self.labels) + 1) == self.labels[:, None]).astype(float)\n",
        "      \n",
        "      self.Y = y_enc.T\n",
        "      \n",
        "      self.m = self.Y.shape[1]\n",
        "      \n",
        "    \n",
        "  def linear_activation_forward(self, A_prev, W, b, activation):\n",
        "      \"\"\"\n",
        "      Arguments:\n",
        "      A_prev -- previous A result from layer l-1, shape of (layer_dims[l-1], m)\n",
        "      W -- weight for layer l shape of (layer_dims[l], layer_dims[l-1])\n",
        "      b -- bias for layer l shape of (layer_dims[l], 1)\n",
        "      activation -- relu/softmax\n",
        "\n",
        "      Returns:\n",
        "      A -- \n",
        "      cache -- \n",
        "      \"\"\"\n",
        "\n",
        "      #Z, linear_cache = linear_forward(A_prev, W, b)\n",
        "      \n",
        "      Z = self.linear_forward(A_prev, W, b)\n",
        "\n",
        "      if activation == \"relu\":\n",
        "        #A, activation_cache = relu(Z)\n",
        "        A = self.relu(Z)\n",
        "      if activation == \"softmax\":\n",
        "        #A, activation_cache = softmax(Z)\n",
        "        A = self.softmax(Z)\n",
        "\n",
        "      #cache = (linear_cache, activation_cache)\n",
        "      return A  \n",
        "    \n",
        "  def initialize_parameters_deep(self):\n",
        "      \"\"\"\n",
        "      Arguments:\n",
        "      layer_dims -- python array containing dimensions of each layer\n",
        "\n",
        "      Returns:\n",
        "      parameters -- dictionary\n",
        "                    Wl -- weight shape of (layer_dims[l], layer_dims[l-1])\n",
        "                    bl -- bias shape of (layer_dims[l],1)\n",
        "\n",
        "      \"\"\"\n",
        "      np.random.seed(1)\n",
        "      #self.parameters = {}\n",
        "\n",
        "      for l in range(1,self.L):\n",
        "        self.parameters['W'+str(l)] = np.random.rand(self.layer_dims[l], self.layer_dims[l-1]) / np.sqrt(self.layer_dims[l-1])\n",
        "        self.parameters['b'+str(l)] = np.zeros((self.layer_dims[l],1))\n",
        "\n",
        "        assert(self.parameters['W'+str(l)].shape == (self.layer_dims[l], self.layer_dims[l-1]))\n",
        "        assert(self.parameters['b'+str(l)].shape == (self.layer_dims[l], 1))\n",
        "\n",
        "    \n",
        "  def linear_forward(self, A, W, b):\n",
        "      \"\"\"\n",
        "      Arguments:\n",
        "      A -- activation result from layer l-1, shape of (layer_dims[l-1], m)\n",
        "      W -- weight for layer l shape of (layer_dims[l], layer_dims[l-1])\n",
        "      b -- bias for layer l shape of (layer_dims[l], 1)\n",
        "\n",
        "      Returns:\n",
        "      Z -- linear result shape of (layer_dims[l], m)\n",
        "      cache -- A,W,b \n",
        "      \"\"\"\n",
        "\n",
        "\n",
        "      #Z=np.dot(W,A) + b\n",
        "\n",
        "      Z = W.dot(A) +b\n",
        "\n",
        "      assert(Z.shape == (W.shape[0], A.shape[1]) )\n",
        "      #cache = (A, W, b)\n",
        "\n",
        "      return Z\n",
        "    \n",
        "    \n",
        "  def relu(self, Z):\n",
        "  \n",
        "      \"\"\"\n",
        "      Arguments:\n",
        "      Z -- output of linear layer, with shape(n,m), n is number of units\n",
        "\n",
        "      Returns:\n",
        "      A -- relu result of Z\n",
        "      cache -- \n",
        "      \"\"\"\n",
        "\n",
        "      A=np.maximum(0,Z)\n",
        "\n",
        "      assert(A.shape == Z.shape)\n",
        "\n",
        "      #cache = Z\n",
        "      return A \n",
        "    \n",
        "    \n",
        "  def softmax(self, Z):\n",
        "      '''\n",
        "      implements softmax funciton\n",
        "\n",
        "      Arguments:\n",
        "      Z -- input as an array of shape(n,1)\n",
        "\n",
        "      Returns:\n",
        "      A -- softmax result of array z, same shape as z\n",
        "      cache -- A. \n",
        "      '''\n",
        "      A=np.exp(Z)/np.sum(np.exp(Z),axis=0)\n",
        "      #cache=Z\n",
        "      assert(A.shape == Z.shape)\n",
        "      return A\n",
        "    \n",
        "\n",
        "\n",
        "    \n",
        "  def L_model_forward(self):\n",
        "      \"\"\"\n",
        "      Arguments:\n",
        "      X -- input data. shape of \n",
        "      parameters -- output from initialize_parameters_deep. dictionary contains:\n",
        "                    Wl -- weight shape of (layer_dims[l], layer_dims[l-1])\n",
        "                    bl -- bias shape of (layer_dims[l],1)\n",
        "\n",
        "      Returns:\n",
        "      AL -- final output of shape (layer_dims[l], m)\n",
        "      \"\"\"\n",
        "\n",
        "      assert(self.X.shape[0] == self.parameters['W1'].shape[1])\n",
        "      \n",
        "      self.caches[\"A0\"] = self.X\n",
        "\n",
        "      for l in np.arange(1,self.L-1):\n",
        "\n",
        "        \n",
        "        self.caches[\"Z\"+str(l)] = self.linear_forward(self.caches[\"A\"+str(l-1)], self.parameters['W'+str(l)], self.parameters['b'+str(l)])\n",
        "        \n",
        "        self.caches[\"A\"+str(l)] = self.relu(self.caches[\"Z\"+str(l)] )\n",
        "\n",
        "      l+=1\n",
        "      \n",
        "      self.caches[\"Z\"+str(l)] = self.linear_forward(self.caches[\"A\"+str(l-1)], self.parameters['W'+str(l)], self.parameters['b'+str(l)])\n",
        "      \n",
        "      self.caches[\"A\"+str(l)] = self.softmax(self.caches[\"Z\"+str(l)])\n",
        "\n",
        "     \n",
        "      self.AL = self.caches[\"A\"+str(self.L-1)]\n",
        "\n",
        "      \n",
        "  def cross_entropy(self):\n",
        "      \"\"\"\n",
        "      Calculate cross entropy\n",
        "\n",
        "      Arguments:\n",
        "      AL -- output of model:probability vector, shape (10, m)\n",
        "      Y -- true label vector, shape of (10,m)\n",
        "\n",
        "      Returns:\n",
        "      cost -- cross entropy cost\n",
        "\n",
        "      \"\"\"\n",
        "\n",
        "      assert (self.AL.shape == self.Y.shape)\n",
        "      self.cost = -np.sum(np.log(self.AL)*self.Y)/self.m\n",
        "\n",
        "      self.cost =np.squeeze(self.cost)\n",
        "      #assert (cost.shape == ())\n",
        "      #return cost\n",
        "    \n",
        "    \n",
        "  def relu_backward(self, dA, Z):\n",
        "      \"\"\"\n",
        "      Implement the backward propagation for a single RELU unit.\n",
        "\n",
        "      Arguments:\n",
        "      dA -- post-activation gradient, of any shape\n",
        "      cache -- 'Z' where we store for computing backward propagation efficiently\n",
        "\n",
        "      Returns:\n",
        "      dZ -- Gradient of the cost with respect to Z\n",
        "      \"\"\"\n",
        "\n",
        "      #Z = cache\n",
        "      dZ = np.array(dA, copy=True) # just converting dz to a correct object.\n",
        "\n",
        "      # When z <= 0, you should set dz to 0 as well. \n",
        "      dZ[Z <= 0] = 0\n",
        "\n",
        "      assert (dZ.shape == Z.shape)\n",
        "\n",
        "      return dZ\n",
        "    \n",
        "  \n",
        "  def softmax_backward(self, Z):\n",
        "      \"\"\"\n",
        "      Z -- linear output Z in current layer l \n",
        "\n",
        "      \"\"\"\n",
        "\n",
        "      dZ = self.softmax(Z)-self.Y\n",
        "      \n",
        "      return dZ\n",
        "    \n",
        "    \n",
        "  def linear_backward(self, dZ, A_prev, W, b):\n",
        "      \"\"\"\n",
        "      Implement the linear portion of backward propagation for a single layer (layer l)\n",
        "\n",
        "      Arguments:\n",
        "      dZ -- Gradient of the cost with respect to the linear output (of current layer l)\n",
        "      cache -- tuple of values (A_prev, W, b) coming from the forward propagation in the current layer\n",
        "      A_prev -- activation result from layer l-1, \n",
        "\n",
        "      Returns:\n",
        "      dA_prev -- Gradient of the cost with respect to the activation (of the previous layer l-1), same shape as A_prev\n",
        "      dW -- Gradient of the cost with respect to W (current layer l), same shape as W\n",
        "      db -- Gradient of the cost with respect to b (current layer l), same shape as b\n",
        "      \"\"\"\n",
        "      #A_prev, W, b = cache\n",
        "      #m = A_prev.shape[1]\n",
        "\n",
        "      dW = 1./self.m * np.dot(dZ,A_prev.T)\n",
        "      db = 1./self.m * np.sum(dZ, axis = 1, keepdims = True)\n",
        "      dA_prev = np.dot(W.T,dZ)\n",
        "\n",
        "      assert (dA_prev.shape == A_prev.shape)\n",
        "      assert (dW.shape == W.shape)\n",
        "      assert (db.shape == b.shape)\n",
        "\n",
        "      return dA_prev, dW, db\n",
        "    \n",
        "    \n",
        "  def L_model_backward(self):\n",
        "      \"\"\"\n",
        "      Implement the backward propagation for the [LINEAR->RELU] * (L-1) -> LINEAR -> SIGMOID group\n",
        "\n",
        "      Arguments:\n",
        "      AL -- probability vector, output of the forward propagation (L_model_forward())\n",
        "      Y -- true \"label\" vector (containing 0 if non-cat, 1 if cat)\n",
        "      caches -- list of caches containing:\n",
        "                  every cache of linear_activation_forward() with \"relu\" (there are (L-1) or them, indexes from 0 to L-2)\n",
        "                  the cache of linear_activation_forward() with \"sigmoid\" (there is one, index L-1)\n",
        "\n",
        "      Returns:\n",
        "      grads -- A dictionary with the gradients\n",
        "               grads[\"dA\" + str(l)] = ... \n",
        "               grads[\"dW\" + str(l)] = ...\n",
        "               grads[\"db\" + str(l)] = ... \n",
        "      \"\"\"\n",
        "\n",
        "\n",
        "      #Y = Y.reshape(AL.shape) # after this line, Y is the same shape as AL\n",
        "\n",
        "      # Initializing the backpropagation\n",
        "      \n",
        "      dAL = - np.divide(self.Y, self.AL) \n",
        "               \n",
        "      self.grads[\"dA\"+str(self.L-1)] = dAL\n",
        "\n",
        "      # Lth layer (SIGMOID -> LINEAR) gradients. Inputs: \"AL, Y, caches\". Outputs: \"grads[\"dAL\"], grads[\"dWL\"], grads[\"dbL\"]\n",
        "      \n",
        "      #current_cache = caches[L-1]\n",
        "\n",
        "               \n",
        "      self.grads[\"dZ\"+str(self.L-1)] = self.softmax_backward(self.caches[\"Z\"+str(self.L-1)])\n",
        "               \n",
        "                              \n",
        "      self.grads[\"dA\"+str(self.L-2)], self.grads[\"dW\"+str(self.L-1)], self.grads[\"db\"+str(self.L-1)] = self.linear_backward(self.grads[\"dZ\"+str(self.L-1)], self.caches[\"A\"+str(self.L-2)], self.parameters[\"W\"+str(self.L-1)], self.parameters[\"b\"+str(self.L-1)])\n",
        "               \n",
        "\n",
        "      for l in reversed(np.arange(1,self.L-1)):\n",
        "          # lth layer: (RELU -> LINEAR) gradients.\n",
        "          #current_cache = caches[l]\n",
        "                                                                               \n",
        "          self.grads[\"dZ\"+str(l)] = self.relu_backward(self.grads[\"dA\"+str(l)], self.caches[\"Z\"+str(l)])\n",
        "                                                                               \n",
        "          self.grads[\"dA\"+str(l-1)], self.grads[\"dW\"+str(l)], self.grads[\"db\"+str(l)] = self.linear_backward(self.grads[\"dZ\"+str(l)], self.caches[\"A\"+str(l-1)], self.parameters[\"W\"+str(l)], self.parameters[\"b\"+str(l)])\n",
        "                                                                       \n",
        "                                                                               \n",
        "  def update_parameters(self, learning_rate):\n",
        "      \"\"\"\n",
        "      Update parameters using gradient descent\n",
        "\n",
        "      Arguments:\n",
        "      parameters -- python dictionary containing your parameters \n",
        "      grads -- python dictionary containing your gradients, output of L_model_backward\n",
        "\n",
        "      Returns:\n",
        "      parameters -- python dictionary containing your updated parameters \n",
        "                    parameters[\"W\" + str(l)] = ... \n",
        "                    parameters[\"b\" + str(l)] = ...\n",
        "      \"\"\"\n",
        "\n",
        "      #L = len(parameters) // 2 # number of layers in the neural network\n",
        "      \n",
        "      \n",
        "\n",
        "      # Update rule for each parameter. Use a for loop.\n",
        "      for l in range(self.L-1):\n",
        "          self.parameters[\"W\" + str(l+1)] = self.parameters[\"W\" + str(l+1)] - learning_rate * self.grads[\"dW\" + str(l+1)]\n",
        "          self.parameters[\"b\" + str(l+1)] = self.parameters[\"b\" + str(l+1)] - learning_rate * self.grads[\"db\" + str(l+1)]\n",
        "   \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  def predict(self):\n",
        "      \"\"\"\n",
        "      This function is used to predict the results of a  L-layer neural network.\n",
        "\n",
        "      Arguments:\n",
        "      X -- data set of examples you would like to label\n",
        "      parameters -- parameters of the trained model\n",
        "\n",
        "      Returns:\n",
        "      p -- predictions for the given dataset X\n",
        "      \"\"\"\n",
        "\n",
        "      self.p=self.AL.argmax(axis=0)\n",
        "\n",
        "\n",
        "      print(\"Accuracy: \"  + str(np.sum((self.p == self.labels)/self.m)))\n",
        "      \n",
        "      #self.accuracy = np.sum((self.p == self.labels)/self.m)\n",
        "      #return self.p\n",
        "    \n",
        "    \n",
        "  def L_layer_model(self, learning_rate = 0.0075, num_iterations = 1000, print_cost=False):\n",
        "      \n",
        "      np.random.seed(1)\n",
        "      \n",
        "      costs = []\n",
        "      \n",
        "      accuracys = []\n",
        "      \n",
        "      self.vectorize_label()\n",
        "      \n",
        "      self.initialize_parameters_deep()\n",
        "      \n",
        "      \n",
        "      for i in range(0, num_iterations):  \n",
        "        \n",
        "          self.L_model_forward()\n",
        "          \n",
        "          self.cross_entropy()\n",
        "          \n",
        "          self.L_model_backward()\n",
        "          \n",
        "          self.update_parameters(learning_rate)\n",
        "          \n",
        "          # Print the cost every 100 training example\n",
        "          if print_cost and i % 100 == 0:      \n",
        "            \n",
        "            \n",
        "            print (\"Cost after iteration %i: %f\" %(i, self.cost))\n",
        "            \n",
        "            #accuracy = self.predict().accuracy\n",
        "            #print (accuracy)\n",
        "            \n",
        "          if print_cost and i % 100 == 0:\n",
        "\n",
        "            costs.append(self.cost)\n",
        "            \n",
        "            #accuracys.append(accuracy)\n",
        "            \n",
        "      self.predict()\n",
        "        \n",
        "      # plot the cost\n",
        "      plt.plot(np.squeeze(costs))\n",
        "      #plt.plot(np.squeeze(accuracys))\n",
        "      plt.ylabel('cost')\n",
        "      plt.xlabel('iterations (per tens)')\n",
        "      plt.title(\"Learning rate =\" + str(learning_rate))\n",
        "      plt.show()\n",
        "\n",
        "\n",
        "    \n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LcrSh-bOha18",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tcpBawj6qyjO",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "05fe86b2-cae8-4d92-9f77-a4064688633b",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1524621455338,
          "user_tz": -600,
          "elapsed": 729,
          "user": {
            "displayName": "Lan",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "106352409797232494979"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "import time\n",
        "start_time = time.time()\n",
        "\n",
        "print(\"--- %s seconds ---\" % (time.time() - start_time))"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--- 6.4849853515625e-05 seconds ---\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "4DZxQNj5gewn",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "outputId": "28ccbf8d-a960-4eec-879c-26f54e3236b2",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1524622274882,
          "user_tz": -600,
          "elapsed": 727585,
          "user": {
            "displayName": "Lan",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "106352409797232494979"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        "  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
        "      name=fn, length=len(uploaded[fn])))"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-21490fd4-29c7-4264-a26e-6b355f16167d\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-21490fd4-29c7-4264-a26e-6b355f16167d\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving train_128.h5 to train_128.h5\n",
            "Saving train_label.h5 to train_label.h5\n",
            "User uploaded file \"train_128.h5\" with length 61442144 bytes\n",
            "User uploaded file \"train_label.h5\" with length 482144 bytes\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "d6aQJ8AmtFyj",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8c2db5d2-d36a-4d1f-f1e5-871dab5856f4",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1524624660950,
          "user_tz": -600,
          "elapsed": 711,
          "user": {
            "displayName": "Lan",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "106352409797232494979"
          }
        }
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(100,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 101
        }
      ]
    },
    {
      "metadata": {
        "id": "EW37fCxzzk7b",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "g8lWlbd3kb85",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 846
        },
        "outputId": "5ee646dd-0eef-447e-8102-a96874364679",
        "executionInfo": {
          "status": "error",
          "timestamp": 1524626668855,
          "user_tz": -600,
          "elapsed": 6805,
          "user": {
            "displayName": "Lan",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "106352409797232494979"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "with h5py.File('train_128.h5','r') as H:\n",
        "    X = np.copy(H['data']).T\n",
        "print(len(data[0,:]))\n",
        "with h5py.File('train_label.h5','r') as H:\n",
        "    labels = np.copy(H['label'])\n",
        "print(\"The first 10 instances: \",label[22],\"\\n\")\n",
        "\n",
        "X_1000 = X[:,0:1000]\n",
        "labels_1000 = labels[0:1000]\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "\n",
        "layer_dims = np.array([128,100,100,100,100,100,10])\n",
        "\n",
        "case_train = Network(layer_dims,X_1000, labels_1000)\n",
        "\n",
        "case_train.L_layer_model(num_iterations=1000, print_cost=True)\n",
        "\n",
        "print(\"--- %s seconds ---\" % (time.time() - start_time))"
      ],
      "execution_count": 161,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "128\n",
            "The first 10 instances:  4 \n",
            "\n",
            "Cost after iteration 0: nan\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:156: RuntimeWarning: overflow encountered in exp\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:156: RuntimeWarning: invalid value encountered in true_divide\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:211: RuntimeWarning: divide by zero encountered in log\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:211: RuntimeWarning: invalid value encountered in multiply\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:303: RuntimeWarning: divide by zero encountered in true_divide\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:303: RuntimeWarning: invalid value encountered in true_divide\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:234: RuntimeWarning: invalid value encountered in less_equal\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Cost after iteration 100: nan\n",
            "Cost after iteration 200: nan\n",
            "Cost after iteration 300: nan\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-161-1bfa3f915e9e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mcase_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNetwork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer_dims\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX_1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels_1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mcase_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mL_layer_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_iterations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint_cost\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"--- %s seconds ---\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-156-df3b84202b43>\u001b[0m in \u001b[0;36mL_layer_model\u001b[0;34m(self, learning_rate, num_iterations, print_cost)\u001b[0m\n\u001b[1;32m    388\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_iterations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 390\u001b[0;31m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mL_model_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    391\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    392\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-156-df3b84202b43>\u001b[0m in \u001b[0;36mL_model_forward\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 183\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaches\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Z\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaches\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"A\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'W'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'b'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaches\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"A\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaches\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Z\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-156-df3b84202b43>\u001b[0m in \u001b[0;36mlinear_forward\u001b[0;34m(self, A, W, b)\u001b[0m\n\u001b[1;32m    116\u001b[0m       \u001b[0;31m#Z=np.dot(W,A) + b\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m       \u001b[0mZ\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mW\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m       \u001b[0;32massert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mZ\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mA\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "6Mk5S2vjmkgZ",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "94802558-1185-4219-963e-ddf7c15cc7dc",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1524625625266,
          "user_tz": -600,
          "elapsed": 734,
          "user": {
            "displayName": "Lan",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "106352409797232494979"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "np.random.randint(10,size=10)"
      ],
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 6, 3, 2, 2, 6, 2, 7, 3, 3])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 131
        }
      ]
    },
    {
      "metadata": {
        "id": "rI1fieXXzoJZ",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "846180d0-25d9-4d84-e219-2335436c49db",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1524626285388,
          "user_tz": -600,
          "elapsed": 720,
          "user": {
            "displayName": "Lan",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "106352409797232494979"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "case1.p\n",
        "\n",
        "   self.p=self.AL.argmax(axis=0)\n",
        "\n",
        "\n",
        "      print(\"Accuracy: \"  + str(np.sum((self.p == self.labels)/self.m)))"
      ],
      "execution_count": 148,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(300,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 148
        }
      ]
    },
    {
      "metadata": {
        "id": "o5Ia-PT_z1fa",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "fab72d47-ac49-4ab7-d6a9-7b8355cae68f",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1524626470228,
          "user_tz": -600,
          "elapsed": 684,
          "user": {
            "displayName": "Lan",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "106352409797232494979"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "np.sum(case1.p == case1.labels)\n",
        "\n",
        "case1.Y.shape"
      ],
      "execution_count": 155,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10, 300)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 155
        }
      ]
    },
    {
      "metadata": {
        "id": "M7UZ_07zc0Dy",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 1305
        },
        "outputId": "81292772-2d10-40a8-80a3-5680bae2c59b",
        "executionInfo": {
          "status": "error",
          "timestamp": 1524627761686,
          "user_tz": -600,
          "elapsed": 32310,
          "user": {
            "displayName": "Lan",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "106352409797232494979"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "start_time = time.time()\n",
        "\n",
        "test_layer_dims = np.array([25,25,50,5])\n",
        "test_X=np.random.rand(25,3000)\n",
        "test_labels= np.random.randint(5,size=3000)\n",
        "\n",
        "\n",
        "case1 = Network(test_layer_dims , test_X, test_labels)\n",
        "\n",
        "case1.L_layer_model(learning_rate = 0.0075, num_iterations=5000, print_cost=True)\n",
        "\n",
        "print(\"--- %s seconds ---\" % (time.time() - start_time))"
      ],
      "execution_count": 187,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cost after iteration 0: 1.921460\n",
            "Cost after iteration 100: 1.608946\n",
            "Cost after iteration 200: 1.608930\n",
            "Cost after iteration 300: 1.608914\n",
            "Cost after iteration 400: 1.608898\n",
            "Cost after iteration 500: 1.608882\n",
            "Cost after iteration 600: 1.608867\n",
            "Cost after iteration 700: 1.608851\n",
            "Cost after iteration 800: 1.608835\n",
            "Cost after iteration 900: 1.608819\n",
            "Cost after iteration 1000: 1.608804\n",
            "Cost after iteration 1100: 1.608788\n",
            "Cost after iteration 1200: 1.608773\n",
            "Cost after iteration 1300: 1.608757\n",
            "Cost after iteration 1400: 1.608742\n",
            "Cost after iteration 1500: 1.608727\n",
            "Cost after iteration 1600: 1.608711\n",
            "Cost after iteration 1700: 1.608696\n",
            "Cost after iteration 1800: 1.608681\n",
            "Cost after iteration 1900: 1.608665\n",
            "Cost after iteration 2000: 1.608650\n",
            "Cost after iteration 2100: 1.608635\n",
            "Cost after iteration 2200: 1.608620\n",
            "Cost after iteration 2300: 1.608605\n",
            "Cost after iteration 2400: 1.608590\n",
            "Cost after iteration 2500: 1.608575\n",
            "Cost after iteration 2600: 1.608560\n",
            "Cost after iteration 2700: 1.608545\n",
            "Cost after iteration 2800: 1.608530\n",
            "Cost after iteration 2900: 1.608515\n",
            "Cost after iteration 3000: 1.608500\n",
            "Cost after iteration 3100: 1.608485\n",
            "Cost after iteration 3200: 1.608470\n",
            "Cost after iteration 3300: 1.608456\n",
            "Cost after iteration 3400: 1.608441\n",
            "Cost after iteration 3500: 1.608426\n",
            "Cost after iteration 3600: 1.608411\n",
            "Cost after iteration 3700: 1.608396\n",
            "Cost after iteration 3800: 1.608382\n",
            "Cost after iteration 3900: 1.608367\n",
            "Cost after iteration 4000: 1.608352\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-187-ae05d9241646>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mcase1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNetwork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_layer_dims\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mtest_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mcase1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mL_layer_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearning_rate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0075\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_iterations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint_cost\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"--- %s seconds ---\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-156-df3b84202b43>\u001b[0m in \u001b[0;36mL_layer_model\u001b[0;34m(self, learning_rate, num_iterations, print_cost)\u001b[0m\n\u001b[1;32m    392\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mL_model_backward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    395\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-156-df3b84202b43>\u001b[0m in \u001b[0;36mL_model_backward\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    322\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"dZ\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu_backward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"dA\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaches\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Z\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 324\u001b[0;31m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"dA\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"dW\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"db\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear_backward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"dZ\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaches\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"A\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"W\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"b\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-156-df3b84202b43>\u001b[0m in \u001b[0;36mlinear_backward\u001b[0;34m(self, dZ, A_prev, W, b)\u001b[0m\n\u001b[1;32m    269\u001b[0m       \u001b[0mdW\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1.\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mm\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdZ\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mA_prev\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m       \u001b[0mdb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1.\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mm\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdZ\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 271\u001b[0;31m       \u001b[0mdA_prev\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdZ\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    272\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m       \u001b[0;32massert\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdA_prev\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mA_prev\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "empTnOADXNsE",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 231
        },
        "outputId": "b9e49e08-398f-467f-9b63-a102f8e85586",
        "executionInfo": {
          "status": "error",
          "timestamp": 1524620918797,
          "user_tz": -600,
          "elapsed": 712,
          "user": {
            "displayName": "Lan",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "106352409797232494979"
          }
        }
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-38-79888331d856>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mcase1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNetwork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer_dims\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mcase1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvectorize_label\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mcase1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitialize_parameters_deep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: __init__() missing 1 required positional argument: 'X'"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "NkfoShBhQIPy",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "97a0b34e-a123-4de6-83a9-ad961821c87b",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1524571845604,
          "user_tz": -600,
          "elapsed": 695,
          "user": {
            "displayName": "Lan",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "106352409797232494979"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "for i in reversed(np.arange(1,5)):\n",
        "  print(i)"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4\n",
            "3\n",
            "2\n",
            "1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "6qzlg4PdZ1cO",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0fb352b4-ea9e-4b9a-e2b0-54cd526b1697",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1524569174785,
          "user_tz": -600,
          "elapsed": 732,
          "user": {
            "displayName": "Lan",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "106352409797232494979"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "range(1,9)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 2, 3, 4, 5, 6, 7, 8]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "metadata": {
        "id": "1Hp5fZ37NlVz",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5f14421d-0421-4cc3-a873-85dac24e5d23",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1524569164998,
          "user_tz": -600,
          "elapsed": 669,
          "user": {
            "displayName": "Lan",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "106352409797232494979"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "np.arange(1,4)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 2, 3])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "metadata": {
        "id": "HFJUpQSzQQYp",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "#back test case\n",
        "A_prev = X\n",
        "W = case1.parameters['W1']\n",
        "b = case1.parameters['b1']\n",
        "dZ=np.random.rand(3,2)\n",
        "\n",
        "m = A_prev.shape[1]\n",
        "\n",
        "dW = 1./m * np.dot(dZ,A_prev.T)\n",
        "db = 1./m * np.sum(dZ, axis = 1, keepdims = True)\n",
        "dA_prev = np.dot(W.T,dZ)\n",
        "\n",
        "assert (dA_prev.shape == A_prev.shape)\n",
        "assert (dW.shape == W.shape)\n",
        "assert (db.shape == b.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eV7U5jb5PAqf",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "3d8b1092-2d2d-4769-dd10-533e51e5b8ba",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1524550109711,
          "user_tz": -600,
          "elapsed": 747,
          "user": {
            "displayName": "Lan",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "106352409797232494979"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "#softmax back test\n",
        "\n",
        "Z_prev=np.random.rand(10,2)\n",
        "\n",
        "dZ = np.exp(Z_prev)/np.sum(np.exp(Z_prev),axis=0)-Y\n",
        "\n",
        "dZ"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.08667124,  0.10417552],\n",
              "       [ 0.17286902,  0.10163095],\n",
              "       [ 0.06679216,  0.12914691],\n",
              "       [-0.91724266,  0.12998553],\n",
              "       [ 0.09662129,  0.13753244],\n",
              "       [ 0.13838783,  0.10114531],\n",
              "       [ 0.07514305,  0.06157375],\n",
              "       [ 0.07401605,  0.06063485],\n",
              "       [ 0.07299804,  0.07267717],\n",
              "       [ 0.13374399, -0.89850242]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 88
        }
      ]
    },
    {
      "metadata": {
        "id": "GVM1MJhrOJ9M",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0a39eb90-cae6-4512-bdbe-65937555e248",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1524572618182,
          "user_tz": -600,
          "elapsed": 681,
          "user": {
            "displayName": "Lan",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "106352409797232494979"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "class shit():\n",
        "  def __init__(self):\n",
        "    self.cost=0\n",
        "  \n",
        "  def addcost(self):\n",
        "    self.cost=1 \n",
        "    \n",
        "m=shit()\n",
        "m.cost"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 83
        }
      ]
    },
    {
      "metadata": {
        "id": "eaakCYzNm1jI",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}